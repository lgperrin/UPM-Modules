# ğŸ“‹ InformaciÃ³n sobre el fichero `docker-compose.yml`

## ğŸ¤” Â¿QuÃ© es este fichero?

Este fichero no es mÃ¡s que la plantilla que considero necesaria como para poder
desplegar la herramienta de Mage AI junto con los escenarios requeridos para el TFG propuesto. En Ã©l,
se definen una serie de servicios que se "comunican" a travÃ©s de una red (_network_).

## ğŸ—£ï¸ ExplicaciÃ³n del Fichero `docker-compose.yml`

* **VersiÃ³n de Docker Compose**: `3.8`
  - Especifica la versiÃ³n de Docker Compose utilizada.

* **Servicios Definidos**
  * Servicio PostgreSQL. Usa la imagen de PostgreSQL versiÃ³n 13 basada en Alpine Linux 3.17.
    - El contenedor se nombra como `postgres-db`.
    - El contenedor se reiniciarÃ¡ automÃ¡ticamente si se detiene `always`.
    - Utiliza el contenedor `./postgres/pgdata:/var/lib/postgresql/data`
    - Persistencia de datos de PostgreSQL en `./postgres/pgdata`.
    - `./postgres/init-magedb.sh:/docker-entrypoint-initdb.d/init-magedb.sh`
    - _Script_ personalizado para inicializar la base de datos.
    - El puerto 5432 del contenedor se mapea al puerto 5432 del _host_ como `5432:5432`.
    - Se hace uso de las variables de entorno `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`
      para configurar los credenciales y la base de datos por defecto.
      
  * Servicio Mage AI. Usa la imagen `mageai/mageai:latest` que es la Ãºltima versiÃ³n de Mage AI.
    - El contenedor se nombra como `mage-ai`.
    - El contenedor se reinicia hasta 5 veces si falla `on-failure:5`.
    - Hace uso del comando `"/app/run_app.sh mage start demo"` para ejecutar el _script_ que inicializa Mage AI en modo _demo_.
    - El volumen `./workspace/demo:/home/src` mapea el directorio de trabajo para la persistencia de datos.
    - El puerto 6789 del contenedor se mapea al puerto 6789 del _host_ como `6789:6789`.
    - Se hace uso de la variable de entorno `MAGE_DATABASE_CONNECTION_URL` que define la URL de conexiÃ³n a la base de datos
      PostgreSQL.

  * **Redes**. La red predeterminada es `mage` que se utiliza como una red externa de conexiÃ³n entre los dos servicios definidos
  con anterioridad.

## ğŸ§™â€â™‚ï¸ IntroducciÃ³n a Mage AI

Mage es una herramienta de _data pipeline_ de cÃ³digo abierto para transformar e integrar datos.

1. [InstalaciÃ³n](###-instalacion)
1. [Features](###-caracteristicas)
1. [Principios de DiseÃ±o](###-principios-de-diseÃ±o)
1. [Abstracciones BÃ¡sicas](###-abstracciones-basicas)

### ğŸƒâ€â™‚ï¸ InstalaciÃ³n

La forma recomendada de instalar la Ãºltima versiÃ³n de Mage es a travÃ©s de Docker con el siguiente comando:

```bash
docker pull mageai/mageai:latest
```
En caso de duda, siempre puedes mirar la documentaciÃ³n [aquÃ­](https://docs.mage.ai/getting-started/setup).

### ğŸ”® CaracterÃ­sticas

|   |   |   |
| --- | --- | --- |
| ğŸ¶ | OrquestaciÃ³n | Programar y administrar _pipelines_ de datos con observabilidad. |
| ğŸ““ | Cuaderno o _Notebook_ | Editor interactivo de Python, SQL y R para codificar _pipelines_ de datos. |
| ğŸ—ï¸ | IntegraciÃ³n de Datos | Sincronizar datos de fuentes de terceros con sus destinos internos. |
| ğŸš° | _Streaming Pipelines_ | Ingerir y transformar datos en tiempo real. |
| â | DBT | Crear, ejecutar y administrar sus modelos dbt con Mage. |

Un ejemplo sencillo de _data pipelines_ puede quedar definido en 3 sencillos archivos (o plantillas), lo que indica un potencial procedimiento de 
buenas prÃ¡cticas en lo que se refiere a la construcciÃ³n de _pipelines_ de datos:

1. Cargar datos:
    ```python
    @data_loader
    def load_csv_from_file():
        return pd.read_csv('default_repo/titanic.csv')
    ```
2. Transformar datos:
    ```python
    @transformer
    def select_columns_from_df(df, *args):
        return df[['Age', 'Fare', 'Survived']]
    ```
3. Exportar datos â
    ```python
    @data_exporter
    def export_titanic_data_to_disk(df) -> None:
        df.to_csv('default_repo/titanic_transformed.csv')
    ```


```mermaid
flowchart TD
    A["Load Data"] --> B["Transform Data"] --> C["Export Data"]
```

### ğŸ”ï¸ Principios de DiseÃ±o

Cada experiencia de usuario y decisiÃ³n de diseÃ±o tÃ©cnico se adhiere a estos principios que ademÃ¡s justifican la elecciÃ³n de Mage AI como herramienta para ejemplificar la construcciÃ³n de _data pipelines_:

|  ID | Principio  |  DescripciÃ³n |
| --- | --- | --- |
| ğŸ’» | Experiencia Sencilla de Usuario | Motor de cÃ³digo abierto que viene con una interfaz de usuario personalizada para crear _data pipelines_. |
| ğŸš¢ | Mejores prÃ¡cticas de ingenierÃ­a integradas | Crear e implementar _data pipelines_ utilizando cÃ³digo modular. |
| ğŸ’³ | Los datos como un ciudadano de primera clase | DiseÃ±ado desde cero especÃ­ficamente para ejecutar flujos de trabajo con uso intensivo de datos. |
| ğŸª | El escalado se simplifica | Analizar y procesar grandes datos rÃ¡pidamente para una iteraciÃ³n rÃ¡pida. |

### ğŸ›¸ Abstracciones BÃ¡sicas

Estos son los conceptos fundamentales que utiliza Mage para operar.

| AbstracciÃ³n  |  DescripciÃ³n |
| --- | --- |
| Proyecto | Como un repositorio en GitHub; aquÃ­ es donde escribes todo tu cÃ³digo. |
| _Pipeline_ | Contiene referencias a todos los bloques de cÃ³digo que desea ejecutar, grÃ¡ficos para visualizar datos y organiza la dependencia entre cada bloque de cÃ³digo. |
| Bloques | Un archivo con cÃ³digo que se puede ejecutar de forma independiente o dentro de una canalizaciÃ³n. |
| Producto de Datos | Cada bloque produce datos despuÃ©s de su ejecuciÃ³n. Estos se denominan productos de datos en Mage. |
| _Trigger_ | Un conjunto de instrucciones que determinan cuÃ¡ndo y cÃ³mo se debe ejecutar una canalizaciÃ³n. |
| _Run_ | Almacena informaciÃ³n sobre cuÃ¡ndo se iniciÃ³, su estado, cuÃ¡ndo se completÃ³, cualquier variable de tiempo de ejecuciÃ³n utilizada en la ejecuciÃ³n de la canalizaciÃ³n o bloque, etc. | 



